---
---

@article{hersche2023factorizers,
  title={Factorizers for Distributed Sparse Block Codes},
  author={Hersche, Michael and Terzic, Aleksandar and Karunaratne, Geethan and Langenegger, Jovin and Pouget, Ang{\'e}line and Cherubini, Giovanni and Benini, Luca and Sebastian, Abu and Rahimi, Abbas},
  journal={Neurosymbolic Artificial Intelligence Journal},
  year={2024},
  url={https://neurosymbolic-ai-journal.com/system/files/nai-paper-713.pdf},
  html={https://neurosymbolic-ai-journal.com/system/files/nai-paper-713.pdf},
  abstract={Distributed sparse block codes (SBCs) exhibit compact representations for encoding and manipulating symbolic data
  structures using fixed-with vectors. One major challenge however is to disentangle, or factorize, such data structures into their
  constituent elements without having to search through all possible combinations. This factorization becomes more challenging
  when queried by noisy SBCs wherein symbol representations are relaxed due to perceptual uncertainty and approximations
  made when modern neural networks generate the query vectors. To address these challenges, we first propose a fast and highly
  accurate method for factorizing a more flexible and hence generalized form of SBCs, dubbed GSBCs. Our iterative factorizer
  introduces a threshold-based nonlinear activation, conditional random sampling, and an ℓ∞-based similarity metric. Its random
  sampling mechanism, in combination with the search in superposition, allows us to analytically determine the expected number
  of decoding iterations, which matches the empirical observations up to the GSBC’s bundling capacity. Secondly, the proposed
  factorizer maintains a high accuracy when queried by noisy product vectors generated using deep convolutional neural networks
  (CNNs). This facilitates its application in replacing the large fully connected layer (FCL) in CNNs, whereby C trainable class
  vectors, or attribute combinations, can be implicitly represented by our factorizer having F-factor codebooks, each with √F
  C fixed codevectors. We provide a methodology to flexibly integrate our factorizer in the classification layer of CNNs with a novel loss
  function. With this integration, the convolutional layers can generate a noisy product vector that our factorizer can still decode,
  whereby the decoded factors can have different interpretations based on downstream tasks. We demonstrate the feasibility of our
  method on four deep CNN architectures over CIFAR-100, ImageNet-1K, and RAVEN datasets. In all use cases, the number of
  parameters and operations are notably reduced compared to the FCL.},
  image={/assets/img/publication_preview/sparse_resonator.png}
}

@inproceedings{pouget2021fast,
  title={Fast and accurate camera scene detection on smartphones},
  author={Pouget, Angeline and Ramesh, Sidharth and Giang, Maximilian and Chandrapalan, Ramithan and Tanner, Toni and Prussing, Moritz and Timofte, Radu and Ignatov, Andrey},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2569--2580},
  year={2021}
}

@inproceedings{ignatov2021fast,
  title={Fast camera image denoising on mobile gpus with deep learning, mobile ai 2021 challenge: Report},
  author={Ignatov, Andrey and Byeoung-Su, Kim and Timofte, Radu and Pouget, Angeline},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={2515--2524},
  year={2021}
}