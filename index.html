<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Angéline N. Pouget </title> <meta name="author" content="Angéline N. Pouget"> <meta name="description" content="My personal website. "> <meta name="keywords" content="angeline, pouget, student, researcher, academic"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/ap.jpg?5fb7256fb6670eb1af646408ab158ed7"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://angelinepouget.github.io/"> <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/news/">news </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/assets/pdf/cv.pdf">cv </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Angéline</span> N. Pouget </h1> <p class="desc">Ambitious student. Curious researcher. Serial intern. Avid reader. Sports enthusiast.</p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/prof_pic-480.webp 480w,/assets/img/prof_pic-800.webp 800w,/assets/img/prof_pic-1400.webp 1400w," sizes="(min-width: 800px) 231.0px, (min-width: 576px) 30vw, 95vw" type="image/webp"> <img src="/assets/img/prof_pic.jpg?d5adf39497b459ea9abaa960ffe7e9bd" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="prof_pic.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div class="clearfix"> <p>Welcome! I’m Angéline, a MSc student at <a href="https://ethz.ch/en.html" rel="external nofollow noopener" target="_blank">ETH Zürich</a>, very curious about the world around me and deeply passionate about diving headfirst into fascinating topics. At the moment, I am mainly focusing on AI research and especially on ensuring the fairness and trustworthiness of machine learning models.</p> <h4 id="research">research</h4> <p>Since early May 2024, I am a research intern at the <a href="https://vectorinstitute.ai/" rel="external nofollow noopener" target="_blank">Vector Institute</a> and a visiting graduate student at the <a href="https://www.utoronto.ca/" rel="external nofollow noopener" target="_blank">University of Toronto</a>, advised by <a href="https://www.papernot.fr/" rel="external nofollow noopener" target="_blank">Nicolas Papernot</a>. Before that, I was a student researcher at <a href="https://deepmind.google/" rel="external nofollow noopener" target="_blank">Google DeepMind</a>, where I focused on evaluating and improving cultural diversity in contrastive vision-language models with <a href="http://lucasb.eyer.be/" rel="external nofollow noopener" target="_blank">Lucas Beyer</a>, <a href="https://sites.google.com/view/xzhai" rel="external nofollow noopener" target="_blank">Xiaohua Zhai</a>, <a href="https://ibomohsin.github.io/" rel="external nofollow noopener" target="_blank">Ibrahim Alabdulmohsin</a> and others. I was also a research assistant at the <a href="https://www.sri.inf.ethz.ch/" rel="external nofollow noopener" target="_blank">SRI Lab</a> with <a href="https://www.sri.inf.ethz.ch/people/martin" rel="external nofollow noopener" target="_blank">Martin Vechev</a>, developing a novel evaluation paradigm for fair representation learning. Prior to this, I worked on neuro-symbolic AI at <a href="https://research.ibm.com/" rel="external nofollow noopener" target="_blank">IBM Research</a> with <a href="https://research.ibm.com/people/abbas-rahimi" rel="external nofollow noopener" target="_blank">Abbas Rahimi</a>, where I developed a factorizer for distributed sparse block codes.</p> <h4 id="other-work-experience">other work experience</h4> <p>Outside of my research endeavours, I have been fortunate enough to wear many different hats and explore various industries. I developed and priced cross-asset structured products and derivatives on the trading floor at <a href="https://www.goldmansachs.com/" rel="external nofollow noopener" target="_blank">Goldman Sachs</a> in London, assisted different teams in solving challenging business problems at <a href="https://www.mckinsey.com/ch/overview" rel="external nofollow noopener" target="_blank">McKinsey &amp; Company</a> and closely collaborated with client stakeholders at <a href="https://www.palantir.com/uk/" rel="external nofollow noopener" target="_blank">Palantir Technologies</a>. As a managing partner at <a href="https://www.campus.founderful.com/" rel="external nofollow noopener" target="_blank">Founderful Campus</a>, I led a team of seven students while we scouted and selected eight promising startups in which we invested CHF 25k each. During my time at ETH, I served as a teaching assistant for four different lectures, during which I prepared and taught weekly exercise sessions, held exam preparation courses and served as a liaison between professors and students.</p> <h4 id="scholarships">scholarships</h4> <p>My Master’s degree studies are fully funded through the <a href="https://ethz.ch/students/en/studies/financial/scholarships/excellencescholarship.html" rel="external nofollow noopener" target="_blank">Excellence Scholarship &amp; Opportunity Programme (ESOP)</a> of ETH Zürich. During my Bachelor’s degree studies, I was generously supported through a <a href="https://www.studyfoundation.ch/our-scholarships/" rel="external nofollow noopener" target="_blank">Werner Siemens Fellowship</a> awarded by the <a href="https://www.studyfoundation.ch/" rel="external nofollow noopener" target="_blank">Swiss Study Foundation</a> and the <a href="https://www.wernersiemens-stiftung.ch/en/" rel="external nofollow noopener" target="_blank">Werner Siemens-Stiftung</a>.</p> </div> <h2> <a href="/news/" style="color: inherit">news</a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">May 24, 2024</th> <td> Very excited to share our <a href="https://arxiv.org/abs/2405.13777" rel="external nofollow noopener" target="_blank">paper</a> on cultural diversity in contrastive vision-language models that I worked on while at <a href="https://deepmind.google/" rel="external nofollow noopener" target="_blank">Google DeepMind</a> with <a href="http://lucasb.eyer.be/" rel="external nofollow noopener" target="_blank">Lucas Beyer</a>, <a href="https://e-bug.github.io/" rel="external nofollow noopener" target="_blank">Emanuele Bugliarello</a>, <a href="https://x.com/brainshawn" rel="external nofollow noopener" target="_blank">Xiao Wang</a>, <a href="https://x.com/AndreasPSteiner" rel="external nofollow noopener" target="_blank">Andreas Steiner</a>, <a href="https://sites.google.com/view/xzhai" rel="external nofollow noopener" target="_blank">Xiaohua Zhai</a> and <a href="https://ibomohsin.github.io/" rel="external nofollow noopener" target="_blank">Ibrahim Alabdulmohsin</a>. </td> </tr> <tr> <th scope="row" style="width: 20%">May 01, 2024</th> <td> Until the end of this year, I will be working with <a href="https://www.papernot.fr/" rel="external nofollow noopener" target="_blank">Nicolas Papernot</a> and the other <a href="https://cleverhans-lab.github.io/" rel="external nofollow noopener" target="_blank">CleverHans Lab</a> team members as a research intern at the <a href="https://vectorinstitute.ai/" rel="external nofollow noopener" target="_blank">Vector Institute</a> and a visiting graduate student at the <a href="https://www.utoronto.ca/" rel="external nofollow noopener" target="_blank">University of Toronto</a>. </td> </tr> <tr> <th scope="row" style="width: 20%">Apr 28, 2024</th> <td> During my Bachelor thesis with <a href="https://research.ibm.com/people/abbas-rahimi" rel="external nofollow noopener" target="_blank">Abbas Rahimi</a> and <a href="https://iis-projects.ee.ethz.ch/index.php/User:Herschmi" rel="external nofollow noopener" target="_blank">Michael Hersche</a> at <a href="https://research.ibm.com/" rel="external nofollow noopener" target="_blank">IBM Research</a>, I developed a sparse resonator network (the full thesis can be found <a href="/assets/pdf/bsc_thesis.pdf">here</a>). The resulting <a href="https://neurosymbolic-ai-journal.com/system/files/nai-paper-713.pdf" rel="external nofollow noopener" target="_blank">paper</a> was just accepted for publication in <a href="https://neurosymbolic-ai-journal.com/" rel="external nofollow noopener" target="_blank">Neurosymbolic Artificial Intelligence</a>. </td> </tr> <tr> <th scope="row" style="width: 20%">Apr 17, 2024</th> <td> I presented some of my research interests at this year’s <a href="https://ethz-foundation.ch/en/spotlight/meet-the-talent-2024/" rel="external nofollow noopener" target="_blank">Meet the Talent</a>, organised by the <a href="https://ethz-foundation.ch/en/" rel="external nofollow noopener" target="_blank">ETH Foundation</a>. </td> </tr> <tr> <th scope="row" style="width: 20%">Mar 24, 2024</th> <td> I was accepted into the 2024 <a href="https://dlrl.ca/" rel="external nofollow noopener" target="_blank">Deep Learning + Reinforcement Learning (DLRL) Summer School</a> taking place in Toronto in July. </td> </tr> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">selected publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge rounded">Preprint</abbr> </div> <div id="pouget2024filter" class="col-sm-8"> <div class="title">No Filter: Cultural and Socioeconomic Diversity in Contrastive Vision-Language Models</div> <div class="author"> <em>Angéline Pouget</em>, Lucas Beyer, Emanuele Bugliarello, Xiao Wang, Andreas Steiner, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Xiaohua Zhai, Ibrahim Alabdulmohsin' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em></em> 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2405.13777" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://arxiv.org/pdf/2405.13777" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>We study cultural and socioeconomic diversity in contrastive vision-language models (VLMs). Using a broad range of benchmark datasets and evaluation metrics, we bring to attention several important findings. First, the common filtering of training data to English image-text pairs disadvantages communities of lower socioeconomic status and negatively impacts cultural understanding. Notably, this performance gap is not captured by – and even at odds with – the currently popular evaluation metrics derived from the Western-centric ImageNet and COCO datasets. Second, pretraining with global, unfiltered data before fine-tuning on English content can improve cultural understanding without sacrificing performance on said popular benchmarks. Third, we introduce the task of geo-localization as a novel evaluation metric to assess cultural diversity in VLMs. Our work underscores the value of using diverse data to create more inclusive multimodal systems and lays the groundwork for developing VLMs that better represent global perspectives.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge rounded">Preprint</abbr> </div> <div id="pouget2024drawing" class="col-sm-8"> <div class="title">Back to the Drawing Board for Fair Representation Learning</div> <div class="author"> <em>Angéline Pouget</em>, Nikola Jovanović, Mark Vero, Robin Staab, and Martin Vechev </div> <div class="periodical"> <em></em> 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2405.18161" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://arxiv.org/pdf/2405.18161" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>The goal of Fair Representation Learning (FRL) is to mitigate biases in machine learning models by learning data representations that enable high accuracy on downstream tasks while minimizing discrimination based on sensitive attributes. The evaluation of FRL methods in many recent works primarily focuses on the tradeoff between downstream fairness and accuracy with respect to a single task that was used to approximate the utility of representations during training (proxy task). This incentivizes retaining only features relevant to the proxy task while discarding all other information. In extreme cases, this can cause the learned representations to collapse to a trivial, binary value, rendering them unusable in transfer settings. In this work, we argue that this approach is fundamentally mismatched with the original motivation of FRL, which arises from settings with many downstream tasks unknown at training time (transfer tasks). To remedy this, we propose to refocus the evaluation protocol of FRL methods primarily around the performance on transfer tasks. A key challenge when conducting such an evaluation is the lack of adequate benchmarks. We address this by formulating four criteria that a suitable evaluation procedure should fulfill. Based on these, we propose TransFair, a benchmark that satisfies these criteria, consisting of novel variations of popular FRL datasets with carefully calibrated transfer tasks. In this setting, we reevaluate state-of-the-art FRL methods, observing that they often overfit to the proxy task, which causes them to underperform on certain transfer tasks. We further highlight the importance of task-agnostic learning signals for FRL methods, as they can lead to more transferrable representations.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge rounded">NAI Journal</abbr> </div> <div id="hersche2023factorizers" class="col-sm-8"> <div class="title">Factorizers for Distributed Sparse Block Codes</div> <div class="author"> Michael Hersche, Aleksandar Terzic, Geethan Karunaratne, Jovin Langenegger, <em>Angéline Pouget</em>, and <span class="more-authors" title="click to view 4 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '4 more authors' ? 'Giovanni Cherubini, Luca Benini, Abu Sebastian, Abbas Rahimi' : '4 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">4 more authors</span> </div> <div class="periodical"> <em>Neurosymbolic Artificial Intelligence Journal</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2303.13957" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://neurosymbolic-ai-journal.com/system/files/nai-paper-713.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>Distributed sparse block codes (SBCs) exhibit compact representations for encoding and manipulating symbolic data structures using fixed-with vectors. One major challenge however is to disentangle, or factorize, such data structures into their constituent elements without having to search through all possible combinations. This factorization becomes more challenging when queried by noisy SBCs wherein symbol representations are relaxed due to perceptual uncertainty and approximations made when modern neural networks generate the query vectors. To address these challenges, we first propose a fast and highly accurate method for factorizing a more flexible and hence generalized form of SBCs, dubbed GSBCs. Our iterative factorizer introduces a threshold-based nonlinear activation, conditional random sampling, and an ℓ∞-based similarity metric. Its random sampling mechanism, in combination with the search in superposition, allows us to analytically determine the expected number of decoding iterations, which matches the empirical observations up to the GSBC’s bundling capacity. Secondly, the proposed factorizer maintains a high accuracy when queried by noisy product vectors generated using deep convolutional neural networks (CNNs). This facilitates its application in replacing the large fully connected layer (FCL) in CNNs, whereby C trainable class vectors, or attribute combinations, can be implicitly represented by our factorizer having F-factor codebooks, each with √F C fixed codevectors. We provide a methodology to flexibly integrate our factorizer in the classification layer of CNNs with a novel loss function. With this integration, the convolutional layers can generate a noisy product vector that our factorizer can still decode, whereby the decoded factors can have different interpretations based on downstream tasks. We demonstrate the feasibility of our method on four deep CNN architectures over CIFAR-100, ImageNet-1K, and RAVEN datasets. In all use cases, the number of parameters and operations are notably reduced compared to the FCL.</p> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%61%6E%67%65%6C%69%6E%65.%70%6F%75%67%65%74@%70%6F%75%67%65%74.%63%68" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=7vjURk0AAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/angelinepouget" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://www.linkedin.com/in/angelinepouget" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="https://twitter.com/angelinepouget" title="X" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-x-twitter"></i></a> </div> <div class="contact-note">Feel free to reach out via email, I am happy to connect. </div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Angéline N. Pouget. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: May 31, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?b7816bd189846d29eded8745f9c4cf77"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>